{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TestCase_Analysis(Ver1.0).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJqV_6jLuBOI",
        "outputId": "1cc3ef9f-92d1-4690-92ac-bf8822dd9ef2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: rembg==1.0.10 in /usr/local/lib/python3.7/dist-packages (1.0.10)\n",
            "Requirement already satisfied: flask==1.1.2 in /usr/local/lib/python3.7/dist-packages (from rembg==1.0.10) (1.1.2)\n",
            "Requirement already satisfied: pillow==7.2.0 in /usr/local/lib/python3.7/dist-packages (from rembg==1.0.10) (7.2.0)\n",
            "Requirement already satisfied: scikit-image==0.17.2 in /usr/local/lib/python3.7/dist-packages (from rembg==1.0.10) (0.17.2)\n",
            "Collecting torchvision==0.7.0\n",
            "  Using cached torchvision-0.7.0-cp37-cp37m-manylinux1_x86_64.whl (5.9 MB)\n",
            "Requirement already satisfied: waitress==1.4.4 in /usr/local/lib/python3.7/dist-packages (from rembg==1.0.10) (1.4.4)\n",
            "Requirement already satisfied: tqdm==4.48.2 in /usr/local/lib/python3.7/dist-packages (from rembg==1.0.10) (4.48.2)\n",
            "Collecting torch==1.6.0\n",
            "  Using cached torch-1.6.0-cp37-cp37m-manylinux1_x86_64.whl (748.8 MB)\n",
            "Requirement already satisfied: requests==2.24.0 in /usr/local/lib/python3.7/dist-packages (from rembg==1.0.10) (2.24.0)\n",
            "Requirement already satisfied: numpy==1.19.1 in /usr/local/lib/python3.7/dist-packages (from rembg==1.0.10) (1.19.1)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask==1.1.2->rembg==1.0.10) (7.1.2)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.7/dist-packages (from flask==1.1.2->rembg==1.0.10) (1.0.1)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask==1.1.2->rembg==1.0.10) (1.1.0)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask==1.1.2->rembg==1.0.10) (2.11.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests==2.24.0->rembg==1.0.10) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests==2.24.0->rembg==1.0.10) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests==2.24.0->rembg==1.0.10) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests==2.24.0->rembg==1.0.10) (2.10)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.17.2->rembg==1.0.10) (2.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.17.2->rembg==1.0.10) (2.6.3)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.17.2->rembg==1.0.10) (1.4.1)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.17.2->rembg==1.0.10) (1.3.0)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.17.2->rembg==1.0.10) (3.2.2)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.17.2->rembg==1.0.10) (2021.11.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0->rembg==1.0.10) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.10.1->flask==1.1.2->rembg==1.0.10) (2.0.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.17.2->rembg==1.0.10) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.17.2->rembg==1.0.10) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.17.2->rembg==1.0.10) (1.4.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.17.2->rembg==1.0.10) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image==0.17.2->rembg==1.0.10) (4.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image==0.17.2->rembg==1.0.10) (1.15.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.11.0\n",
            "    Uninstalling torch-1.11.0:\n",
            "      Successfully uninstalled torch-1.11.0\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.12.0\n",
            "    Uninstalling torchvision-0.12.0:\n",
            "      Successfully uninstalled torchvision-0.12.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.6.0 which is incompatible.\n",
            "torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.6.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.6.0 torchvision-0.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install rembg==1.0.10"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install easyocr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJfuLla0uHTT",
        "outputId": "adb36516-1873-49c4-9010-316a8288dc6d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: easyocr in /usr/local/lib/python3.7/dist-packages (1.4.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from easyocr) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from easyocr) (1.19.1)\n",
            "Requirement already satisfied: opencv-python-headless<=4.5.4.60 in /usr/local/lib/python3.7/dist-packages (from easyocr) (4.5.4.60)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from easyocr) (1.6.0)\n",
            "Requirement already satisfied: python-bidi in /usr/local/lib/python3.7/dist-packages (from easyocr) (0.4.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from easyocr) (7.2.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from easyocr) (6.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from easyocr) (0.17.2)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.7/dist-packages (from easyocr) (0.7.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch->easyocr) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from python-bidi->easyocr) (1.15.0)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->easyocr) (2.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->easyocr) (2.6.3)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->easyocr) (1.3.0)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->easyocr) (3.2.2)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->easyocr) (2021.11.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->easyocr) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->easyocr) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->easyocr) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->easyocr) (1.4.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->easyocr) (4.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive\n",
        "!git clone https://github.com/ultralytics/yolov5.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BglxzmJWuIoC",
        "outputId": "879623ac-8861-480c-d7e1-d937cc6d4e74"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n",
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 12168, done.\u001b[K\n",
            "remote: Total 12168 (delta 0), reused 0 (delta 0), pack-reused 12168\u001b[K\n",
            "Receiving objects: 100% (12168/12168), 11.93 MiB | 7.51 MiB/s, done.\n",
            "Resolving deltas: 100% (8427/8427), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/yolov5/\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpSyn15JuJrm",
        "outputId": "2ad81a6a-b05f-4978-be07-aaa634e67735"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/yolov5\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (1.19.1)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (4.1.2.30)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (7.2.0)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (6.0)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (2.24.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (1.4.1)\n",
            "Collecting torch>=1.7.0\n",
            "  Using cached torch-1.11.0-cp37-cp37m-manylinux1_x86_64.whl (750.6 MB)\n",
            "Collecting torchvision>=0.8.1\n",
            "  Using cached torchvision-0.12.0-cp37-cp37m-manylinux1_x86_64.whl (21.0 MB)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 14)) (4.48.2)\n",
            "Requirement already satisfied: protobuf<=3.20.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 15)) (3.17.3)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 18)) (2.8.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 22)) (1.3.5)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 23)) (0.11.2)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 35)) (5.5.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 36)) (5.4.8)\n",
            "Requirement already satisfied: thop in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 37)) (0.0.31.post2005241907)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (1.4.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (0.11.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 10)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 10)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 10)) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 10)) (2.10)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7.0->-r requirements.txt (line 12)) (4.2.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<=3.20.1->-r requirements.txt (line 15)) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.46.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (0.37.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (57.4.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.8.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (3.3.7)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 22)) (2022.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 18)) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 18)) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 18)) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 18)) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 18)) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 18)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 18)) (3.2.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 35)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 35)) (0.7.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 35)) (2.6.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 35)) (5.1.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 35)) (1.0.18)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 35)) (0.8.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 35)) (4.8.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->-r requirements.txt (line 35)) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->-r requirements.txt (line 35)) (0.7.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.6.0\n",
            "    Uninstalling torch-1.6.0:\n",
            "      Successfully uninstalled torch-1.6.0\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.7.0\n",
            "    Uninstalling torchvision-0.7.0:\n",
            "      Successfully uninstalled torchvision-0.7.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "rembg 1.0.10 requires torch==1.6.0, but you have torch 1.11.0 which is incompatible.\n",
            "rembg 1.0.10 requires torchvision==0.7.0, but you have torchvision 0.12.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.11.0 torchvision-0.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "from PIL import Image\n",
        "from rembg.bg import remove\n",
        "from IPython.display import Image\n",
        "from sklearn.cluster import KMeans\n",
        "from collections import OrderedDict\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import os\n",
        "import easyocr\n",
        "import easydict\n",
        "import argparse\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def yoloExe(img):\n",
        "    # %cd /content/yolov5/\n",
        "    %cd /content/drive/MyDrive/yolov5/\n",
        "    img_list = glob(img)\n",
        "\n",
        "    val_img_path = img_list[0]\n",
        "\n",
        "    # weights_path = '/content/pill_yolo.pt'\n",
        "    weights_path = '/content/drive/MyDrive/pill_yolo.pt'\n",
        "\n",
        "    !python detect.py --weights \"{weights_path}\" --img 416 --conf 0.5 --source \"{val_img_path}\" --line-thickness 1 --save-crop\n",
        "\n",
        "    detect_img_path = img\n",
        "    Image(os.path.join(detect_img_path, os.path.basename(val_img_path)))\n",
        "\n",
        "\n",
        "def main(): #메인함수\n",
        "    #제형 구하는 부분\n",
        "    path = '/content/images/' # 경로 변경1\n",
        "    file_list = os.listdir(path)\n",
        "    file_list_py = [file for file in file_list if file.endswith('.jpg')] ##\n",
        "    for i in range(len(file_list_py)):\n",
        "        path_str = '/content/images/' + (str)(i+1) + '.jpg'\n",
        "        yoloExe(path_str) #YOLO 함수 호출 #이미지 경로에 사용자가 촬영, 선택한 이미지 경로 넣어야함\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\t  main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84gNvWu7uLgn",
        "outputId": "1a4d4c95-bc5e-4402-ec32-10802ae5fbf0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/yolov5\n",
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/drive/MyDrive/pill_yolo.pt'], source=/content/images/1.jpg, data=data/coco128.yaml, imgsz=[416, 416], conf_thres=0.5, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=True, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=1, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
            "YOLOv5 🚀 v6.1-242-ga80dd66 Python-3.7.13 torch-1.11.0+cu102 CPU\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7012822 parameters, 0 gradients\n",
            "image 1/1 /content/images/1.jpg: 416x320 1 pill, Done. (0.181s)\n",
            "Speed: 0.6ms pre-process, 181.5ms inference, 0.9ms NMS per image at shape (1, 3, 416, 416)\n",
            "Results saved to \u001b[1mruns/detect/exp\u001b[0m\n",
            "/content/drive/MyDrive/yolov5\n",
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/drive/MyDrive/pill_yolo.pt'], source=/content/images/2.jpg, data=data/coco128.yaml, imgsz=[416, 416], conf_thres=0.5, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=True, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=1, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
            "YOLOv5 🚀 v6.1-242-ga80dd66 Python-3.7.13 torch-1.11.0+cu102 CPU\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7012822 parameters, 0 gradients\n",
            "image 1/1 /content/images/2.jpg: 416x320 1 pill, Done. (0.195s)\n",
            "Speed: 0.9ms pre-process, 194.9ms inference, 1.2ms NMS per image at shape (1, 3, 416, 416)\n",
            "Results saved to \u001b[1mruns/detect/exp2\u001b[0m\n",
            "/content/drive/MyDrive/yolov5\n",
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/drive/MyDrive/pill_yolo.pt'], source=/content/images/3.jpg, data=data/coco128.yaml, imgsz=[416, 416], conf_thres=0.5, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=True, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=1, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
            "YOLOv5 🚀 v6.1-242-ga80dd66 Python-3.7.13 torch-1.11.0+cu102 CPU\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7012822 parameters, 0 gradients\n",
            "image 1/1 /content/images/3.jpg: 416x320 Done. (0.185s)\n",
            "Speed: 0.9ms pre-process, 185.3ms inference, 0.2ms NMS per image at shape (1, 3, 416, 416)\n",
            "Results saved to \u001b[1mruns/detect/exp3\u001b[0m\n",
            "/content/drive/MyDrive/yolov5\n",
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/drive/MyDrive/pill_yolo.pt'], source=/content/images/4.jpg, data=data/coco128.yaml, imgsz=[416, 416], conf_thres=0.5, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=True, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=1, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
            "YOLOv5 🚀 v6.1-242-ga80dd66 Python-3.7.13 torch-1.11.0+cu102 CPU\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7012822 parameters, 0 gradients\n",
            "image 1/1 /content/images/4.jpg: 416x320 1 pill, Done. (0.193s)\n",
            "Speed: 1.1ms pre-process, 193.1ms inference, 0.8ms NMS per image at shape (1, 3, 416, 416)\n",
            "Results saved to \u001b[1mruns/detect/exp4\u001b[0m\n",
            "/content/drive/MyDrive/yolov5\n",
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/drive/MyDrive/pill_yolo.pt'], source=/content/images/5.jpg, data=data/coco128.yaml, imgsz=[416, 416], conf_thres=0.5, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=True, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=1, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
            "YOLOv5 🚀 v6.1-242-ga80dd66 Python-3.7.13 torch-1.11.0+cu102 CPU\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7012822 parameters, 0 gradients\n",
            "image 1/1 /content/images/5.jpg: 416x320 1 pill, Done. (0.209s)\n",
            "Speed: 0.6ms pre-process, 209.0ms inference, 0.9ms NMS per image at shape (1, 3, 416, 416)\n",
            "Results saved to \u001b[1mruns/detect/exp5\u001b[0m\n",
            "/content/drive/MyDrive/yolov5\n",
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/drive/MyDrive/pill_yolo.pt'], source=/content/images/6.jpg, data=data/coco128.yaml, imgsz=[416, 416], conf_thres=0.5, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=True, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=1, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
            "YOLOv5 🚀 v6.1-242-ga80dd66 Python-3.7.13 torch-1.11.0+cu102 CPU\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7012822 parameters, 0 gradients\n",
            "image 1/1 /content/images/6.jpg: 416x320 Done. (0.308s)\n",
            "Speed: 0.8ms pre-process, 308.4ms inference, 0.5ms NMS per image at shape (1, 3, 416, 416)\n",
            "Results saved to \u001b[1mruns/detect/exp6\u001b[0m\n",
            "/content/drive/MyDrive/yolov5\n",
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/drive/MyDrive/pill_yolo.pt'], source=/content/images/7.jpg, data=data/coco128.yaml, imgsz=[416, 416], conf_thres=0.5, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=True, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=1, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
            "YOLOv5 🚀 v6.1-242-ga80dd66 Python-3.7.13 torch-1.11.0+cu102 CPU\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7012822 parameters, 0 gradients\n",
            "image 1/1 /content/images/7.jpg: 416x320 Done. (0.184s)\n",
            "Speed: 0.6ms pre-process, 184.4ms inference, 0.2ms NMS per image at shape (1, 3, 416, 416)\n",
            "Results saved to \u001b[1mruns/detect/exp7\u001b[0m\n",
            "/content/drive/MyDrive/yolov5\n",
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/drive/MyDrive/pill_yolo.pt'], source=/content/images/8.jpg, data=data/coco128.yaml, imgsz=[416, 416], conf_thres=0.5, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=True, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=1, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
            "YOLOv5 🚀 v6.1-242-ga80dd66 Python-3.7.13 torch-1.11.0+cu102 CPU\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7012822 parameters, 0 gradients\n",
            "image 1/1 /content/images/8.jpg: 320x416 1 pill, Done. (0.180s)\n",
            "Speed: 0.6ms pre-process, 180.1ms inference, 0.7ms NMS per image at shape (1, 3, 416, 416)\n",
            "Results saved to \u001b[1mruns/detect/exp8\u001b[0m\n",
            "/content/drive/MyDrive/yolov5\n",
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/drive/MyDrive/pill_yolo.pt'], source=/content/images/9.jpg, data=data/coco128.yaml, imgsz=[416, 416], conf_thres=0.5, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=True, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=1, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
            "YOLOv5 🚀 v6.1-242-ga80dd66 Python-3.7.13 torch-1.11.0+cu102 CPU\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7012822 parameters, 0 gradients\n",
            "image 1/1 /content/images/9.jpg: 320x416 1 pill, Done. (0.186s)\n",
            "Speed: 1.0ms pre-process, 186.4ms inference, 0.9ms NMS per image at shape (1, 3, 416, 416)\n",
            "Results saved to \u001b[1mruns/detect/exp9\u001b[0m\n",
            "/content/drive/MyDrive/yolov5\n",
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/drive/MyDrive/pill_yolo.pt'], source=/content/images/10.jpg, data=data/coco128.yaml, imgsz=[416, 416], conf_thres=0.5, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=True, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=1, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
            "YOLOv5 🚀 v6.1-242-ga80dd66 Python-3.7.13 torch-1.11.0+cu102 CPU\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7012822 parameters, 0 gradients\n",
            "image 1/1 /content/images/10.jpg: 320x416 1 pill, Done. (0.180s)\n",
            "Speed: 0.8ms pre-process, 180.0ms inference, 0.8ms NMS per image at shape (1, 3, 416, 416)\n",
            "Results saved to \u001b[1mruns/detect/exp10\u001b[0m\n",
            "/content/drive/MyDrive/yolov5\n",
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/drive/MyDrive/pill_yolo.pt'], source=/content/images/11.jpg, data=data/coco128.yaml, imgsz=[416, 416], conf_thres=0.5, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=True, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=1, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
            "YOLOv5 🚀 v6.1-242-ga80dd66 Python-3.7.13 torch-1.11.0+cu102 CPU\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7012822 parameters, 0 gradients\n",
            "image 1/1 /content/images/11.jpg: 320x416 1 pill, Done. (0.183s)\n",
            "Speed: 0.7ms pre-process, 183.3ms inference, 0.8ms NMS per image at shape (1, 3, 416, 416)\n",
            "Results saved to \u001b[1mruns/detect/exp11\u001b[0m\n",
            "/content/drive/MyDrive/yolov5\n",
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/drive/MyDrive/pill_yolo.pt'], source=/content/images/12.jpg, data=data/coco128.yaml, imgsz=[416, 416], conf_thres=0.5, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=True, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=1, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
            "YOLOv5 🚀 v6.1-242-ga80dd66 Python-3.7.13 torch-1.11.0+cu102 CPU\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7012822 parameters, 0 gradients\n",
            "image 1/1 /content/images/12.jpg: 320x416 1 pill, Done. (0.193s)\n",
            "Speed: 0.7ms pre-process, 193.0ms inference, 1.2ms NMS per image at shape (1, 3, 416, 416)\n",
            "Results saved to \u001b[1mruns/detect/exp12\u001b[0m\n",
            "/content/drive/MyDrive/yolov5\n",
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/drive/MyDrive/pill_yolo.pt'], source=/content/images/13.jpg, data=data/coco128.yaml, imgsz=[416, 416], conf_thres=0.5, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=True, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=1, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
            "YOLOv5 🚀 v6.1-242-ga80dd66 Python-3.7.13 torch-1.11.0+cu102 CPU\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7012822 parameters, 0 gradients\n",
            "image 1/1 /content/images/13.jpg: 320x416 1 pill, Done. (0.192s)\n",
            "Speed: 0.7ms pre-process, 191.6ms inference, 1.2ms NMS per image at shape (1, 3, 416, 416)\n",
            "Results saved to \u001b[1mruns/detect/exp13\u001b[0m\n",
            "/content/drive/MyDrive/yolov5\n",
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/drive/MyDrive/pill_yolo.pt'], source=/content/images/14.jpg, data=data/coco128.yaml, imgsz=[416, 416], conf_thres=0.5, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=True, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=1, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
            "YOLOv5 🚀 v6.1-242-ga80dd66 Python-3.7.13 torch-1.11.0+cu102 CPU\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7012822 parameters, 0 gradients\n",
            "image 1/1 /content/images/14.jpg: 416x320 1 pill, Done. (0.183s)\n",
            "Speed: 0.6ms pre-process, 182.6ms inference, 0.7ms NMS per image at shape (1, 3, 416, 416)\n",
            "Results saved to \u001b[1mruns/detect/exp14\u001b[0m\n",
            "/content/drive/MyDrive/yolov5\n",
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/drive/MyDrive/pill_yolo.pt'], source=/content/images/15.jpg, data=data/coco128.yaml, imgsz=[416, 416], conf_thres=0.5, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=True, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=1, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
            "YOLOv5 🚀 v6.1-242-ga80dd66 Python-3.7.13 torch-1.11.0+cu102 CPU\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7012822 parameters, 0 gradients\n",
            "image 1/1 /content/images/15.jpg: 416x320 1 pill, Done. (0.183s)\n",
            "Speed: 0.7ms pre-process, 182.6ms inference, 0.7ms NMS per image at shape (1, 3, 416, 416)\n",
            "Results saved to \u001b[1mruns/detect/exp15\u001b[0m\n",
            "/content/drive/MyDrive/yolov5\n",
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/drive/MyDrive/pill_yolo.pt'], source=/content/images/16.jpg, data=data/coco128.yaml, imgsz=[416, 416], conf_thres=0.5, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=True, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=1, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
            "YOLOv5 🚀 v6.1-242-ga80dd66 Python-3.7.13 torch-1.11.0+cu102 CPU\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7012822 parameters, 0 gradients\n",
            "image 1/1 /content/images/16.jpg: 416x320 1 pill, Done. (0.187s)\n",
            "Speed: 0.7ms pre-process, 187.2ms inference, 0.7ms NMS per image at shape (1, 3, 416, 416)\n",
            "Results saved to \u001b[1mruns/detect/exp16\u001b[0m\n",
            "/content/drive/MyDrive/yolov5\n",
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/drive/MyDrive/pill_yolo.pt'], source=/content/images/17.jpg, data=data/coco128.yaml, imgsz=[416, 416], conf_thres=0.5, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=True, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=1, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
            "YOLOv5 🚀 v6.1-242-ga80dd66 Python-3.7.13 torch-1.11.0+cu102 CPU\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7012822 parameters, 0 gradients\n",
            "image 1/1 /content/images/17.jpg: 320x416 1 pill, Done. (0.184s)\n",
            "Speed: 0.7ms pre-process, 184.0ms inference, 0.7ms NMS per image at shape (1, 3, 416, 416)\n",
            "Results saved to \u001b[1mruns/detect/exp17\u001b[0m\n",
            "/content/drive/MyDrive/yolov5\n",
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/drive/MyDrive/pill_yolo.pt'], source=/content/images/18.jpg, data=data/coco128.yaml, imgsz=[416, 416], conf_thres=0.5, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=True, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=1, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
            "YOLOv5 🚀 v6.1-242-ga80dd66 Python-3.7.13 torch-1.11.0+cu102 CPU\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7012822 parameters, 0 gradients\n",
            "image 1/1 /content/images/18.jpg: 416x320 1 pill, Done. (0.230s)\n",
            "Speed: 1.7ms pre-process, 230.1ms inference, 0.8ms NMS per image at shape (1, 3, 416, 416)\n",
            "Results saved to \u001b[1mruns/detect/exp18\u001b[0m\n",
            "/content/drive/MyDrive/yolov5\n",
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/drive/MyDrive/pill_yolo.pt'], source=/content/images/19.jpg, data=data/coco128.yaml, imgsz=[416, 416], conf_thres=0.5, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=True, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=1, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
            "YOLOv5 🚀 v6.1-242-ga80dd66 Python-3.7.13 torch-1.11.0+cu102 CPU\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7012822 parameters, 0 gradients\n",
            "image 1/1 /content/images/19.jpg: 416x320 1 pill, Done. (0.202s)\n",
            "Speed: 0.7ms pre-process, 201.7ms inference, 0.8ms NMS per image at shape (1, 3, 416, 416)\n",
            "Results saved to \u001b[1mruns/detect/exp19\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP4. 실행 전, /content/yolov5/runs/detect/exp -> exp1으로 파일명 바꿨는지 꼭 확인할것!\n",
        "\n",
        "global j\n",
        "global ERRORLIST\n",
        "j = 1\n",
        "\n",
        "def rmBg(path):\n",
        "    global j\n",
        "    input_path = path\n",
        "    output_path = '/content/drive/MyDrive/remove_images/' + (str)(j) + 'rmbg.jpg'\n",
        "\n",
        "    with open(input_path, 'rb') as i:\n",
        "        with open(output_path, 'wb') as o:\n",
        "            input = i.read()\n",
        "            output = remove(input)\n",
        "            o.write(output)\n",
        "\n",
        "def main(): #메인함수\n",
        "    %cd /content/drive/MyDrive\n",
        "    global j\n",
        "    global ERRORLIST\n",
        "    ERRORLIST = list()\n",
        "    path2 = '/content/images/' # 경로 변경3.(Shape_Name)\n",
        "    file_list2 = os.listdir(path2)\n",
        "    file_list_py2 = [file for file in file_list2 if file.endswith('.jpg')] ##\n",
        "    for i in range(len(file_list_py2)):\n",
        "      print(\"현재 \"+str(i+1)+\"번째 이미지에 대한 작업 수행중입니다.\")\n",
        "      try:\n",
        "        path_str2 = '/content/drive/MyDrive/yolov5/runs/detect/exp' + (str)(i+1) + '/crops/pill/'  + (str)(i+1) + '.jpg'\n",
        "        rmBg(path_str2)\n",
        "      except Exception as e:\n",
        "        print(\"[ERROR] \"+str(i+1)+\"번째 이미지에 대해 에러가 발생했습니다.\")\n",
        "        print(e)\n",
        "        ERRORLIST.append(e)\n",
        "        continue\n",
        "      finally:\n",
        "        j = j + 1\n",
        "    print(ERRORLIST)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\t  main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gk4UEsC91wz_",
        "outputId": "9716af76-5706-4af6-dd49-d5b35275f3dc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n",
            "현재 1번째 이미지에 대한 작업 수행중입니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:780: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.\n",
            "  warnings.warn(\"Note that order of the arguments: ceil_mode and return_indices will change\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "현재 2번째 이미지에 대한 작업 수행중입니다.\n",
            "현재 3번째 이미지에 대한 작업 수행중입니다.\n",
            "[ERROR] 3번째 이미지에 대해 에러가 발생했습니다.\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/yolov5/runs/detect/exp3/crops/pill/3.jpg'\n",
            "현재 4번째 이미지에 대한 작업 수행중입니다.\n",
            "현재 5번째 이미지에 대한 작업 수행중입니다.\n",
            "현재 6번째 이미지에 대한 작업 수행중입니다.\n",
            "[ERROR] 6번째 이미지에 대해 에러가 발생했습니다.\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/yolov5/runs/detect/exp6/crops/pill/6.jpg'\n",
            "현재 7번째 이미지에 대한 작업 수행중입니다.\n",
            "[ERROR] 7번째 이미지에 대해 에러가 발생했습니다.\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/yolov5/runs/detect/exp7/crops/pill/7.jpg'\n",
            "현재 8번째 이미지에 대한 작업 수행중입니다.\n",
            "현재 9번째 이미지에 대한 작업 수행중입니다.\n",
            "현재 10번째 이미지에 대한 작업 수행중입니다.\n",
            "현재 11번째 이미지에 대한 작업 수행중입니다.\n",
            "현재 12번째 이미지에 대한 작업 수행중입니다.\n",
            "현재 13번째 이미지에 대한 작업 수행중입니다.\n",
            "현재 14번째 이미지에 대한 작업 수행중입니다.\n",
            "현재 15번째 이미지에 대한 작업 수행중입니다.\n",
            "현재 16번째 이미지에 대한 작업 수행중입니다.\n",
            "현재 17번째 이미지에 대한 작업 수행중입니다.\n",
            "현재 18번째 이미지에 대한 작업 수행중입니다.\n",
            "현재 19번째 이미지에 대한 작업 수행중입니다.\n",
            "[FileNotFoundError(2, 'No such file or directory'), FileNotFoundError(2, 'No such file or directory'), FileNotFoundError(2, 'No such file or directory')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "from PIL import Image\n",
        "from rembg.bg import remove\n",
        "from IPython.display import Image\n",
        "from sklearn.cluster import KMeans\n",
        "from collections import OrderedDict\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import os\n",
        "import easyocr\n",
        "import easydict\n",
        "import argparse\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "result = []\n",
        "H = []\n",
        "S = []\n",
        "V = []\n",
        "Sum = []\n",
        "tmp = []\n",
        "\n",
        "def setLabel(img, pts, label): #비율 계산에 사용되는 레이블 함수\n",
        "    (x, y, w, h) = cv2.boundingRect(pts)\n",
        "    pt1 = (x, y)\n",
        "    pt2 = (x + w, y + h)\n",
        "    cv2.rectangle(img, pt1, pt2, (0, 255, 0), 2)\n",
        "    cv2.putText(img, label, (pt1[0], pt1[1]-3), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255))\n",
        "    return '/content/rmbg.jpg'\n",
        "\n",
        "def binary(path):\n",
        "    img = cv2.imread(path)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    ret, dst = cv2.threshold (gray, 2, 255, cv2.THRESH_BINARY)\n",
        "    cv2.imwrite(\"/content/binary.jpg\", dst)\n",
        "\n",
        "    img = cv2.imread(\"/content/binary.jpg\")\n",
        "    k = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
        "    # 팽창 연산 적용\n",
        "    dilate = cv2.dilate(img, k)\n",
        "    cv2.imwrite(\"/content/dilate.jpg\", dilate)\n",
        "\n",
        "    img2 = cv2.imread(\"/content/dilate.jpg\")\n",
        "    dilate2 = cv2.dilate(img2, k)\n",
        "    cv2.imwrite(\"/content/dilate2.jpg\", dilate2)\n",
        "\n",
        "    return '/content/dilate2.jpg'\n",
        "\n",
        "def reverse(path): #이진화된 이미지 반전시키는 함수\n",
        "    img = cv2.imread(path)\n",
        "    out = img.copy()\n",
        "    out = 255 - out\n",
        "    cv2.imwrite(\"/content/pill.jpg\", out)\n",
        "    return '/content/pill.jpg'\n",
        "\n",
        "def cont(path): #원, 타원, 장방형의 각형을 알려주는 함수\n",
        "    img = cv2.imread(path)\n",
        "    img2 = img.copy()\n",
        "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    res, thr = cv2.threshold(img_gray, 127, 255, cv2.THRESH_BINARY)\n",
        "    contours, hierarchy = cv2.findContours(thr, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    cnt = contours[0]\n",
        "    cv2.drawContours(img, [cnt], -1, (255, 255, 0), 2)\n",
        "\n",
        "    epsilon2 =  0.005 * cv2.arcLength(cnt, True)\n",
        "    approx2 = cv2.approxPolyDP(cnt, epsilon2, True)\n",
        "    cv2.drawContours(img2, [approx2], -1, (0, 255, 0), 3)\n",
        "\n",
        "    #detect(path)\n",
        "    #print(len(approx2))\n",
        "    if len(approx2) == 4:\n",
        "        detect_4(path)\n",
        "    elif len(approx2) == 5 or len(approx2) == 6 or len(approx2) == 7:\n",
        "        detect_5to7(path)\n",
        "    elif len(approx2) == 8 or len(approx2) == 9 or len(approx2) == 10:\n",
        "        detect_8to10(path)\n",
        "    elif len(approx2) == 11 or len(approx2) == 12:\n",
        "        detect_11to12(path)\n",
        "    elif len(approx2) == 13 or len(approx2) == 14:\n",
        "        detect_13to14(path)\n",
        "    elif len(approx2) == 15 or len(approx2) == 16:\n",
        "        detect_15to16(path)\n",
        "    elif len(approx2) >= 17:\n",
        "        detect_17to21(path)\n",
        "\n",
        "def detect_4(path):\n",
        "    src = cv2.imread(reverse(path))\n",
        "    dst = src.copy()\n",
        "\n",
        "    gray = cv2.cvtColor(src, cv2.COLOR_RGB2GRAY)\n",
        "    ret, binary = cv2.threshold(gray, 10, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "    contours, hierarchy = cv2.findContours(binary, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)\n",
        "    for i in contours:\n",
        "        M = cv2.moments(i)\n",
        "        cX = int(M['m10'] / M['m00'])\n",
        "        cY = int(M['m01'] / M['m00'])\n",
        "        \n",
        "        cv2.circle(dst, (cX, cY), 3, (0, 0, 255), -1)\n",
        "        cv2.drawContours(dst, [i], 0, (0, 0, 255), 2)\n",
        "\n",
        "        setLabel(dst, i, '')\n",
        "        (x, y, w, h) = cv2.boundingRect(i)\n",
        "    if w > h:\n",
        "      ratio = h / w\n",
        "    elif h > w:\n",
        "      ratio = w / h\n",
        "    elif h == w:\n",
        "      ratio = h / w\n",
        "\n",
        "    if ratio > 0.1 and ratio <= 0.45:\n",
        "        result.append(\"장방형\")\n",
        "    elif ratio > 0.45 and ratio <= 0.90:\n",
        "        result.append(\"타원형\")\n",
        "    elif ratio > 0.9 and ratio <= 0.95:\n",
        "        result.append(\"사각형\")\n",
        "    elif ratio > 0.95 and ratio <= 1.0:\n",
        "        result.append(\"원형\")\n",
        "\n",
        "def detect_5to7(path):\n",
        "    src = cv2.imread(reverse(path))\n",
        "    dst = src.copy()\n",
        "\n",
        "    gray = cv2.cvtColor(src, cv2.COLOR_RGB2GRAY)\n",
        "    ret, binary = cv2.threshold(gray, 10, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "    contours, hierarchy = cv2.findContours(binary, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)\n",
        "    for i in contours:\n",
        "        M = cv2.moments(i)\n",
        "        cX = int(M['m10'] / M['m00'])\n",
        "        cY = int(M['m01'] / M['m00'])\n",
        "        \n",
        "        cv2.circle(dst, (cX, cY), 3, (0, 0, 255), -1)\n",
        "        cv2.drawContours(dst, [i], 0, (0, 0, 255), 2)\n",
        "\n",
        "        setLabel(dst, i, '')\n",
        "        (x, y, w, h) = cv2.boundingRect(i)\n",
        "    if w > h:\n",
        "      ratio = h / w\n",
        "    elif h > w:\n",
        "      ratio = w / h\n",
        "    elif h == w:\n",
        "      ratio = h / w\n",
        "\n",
        "    if ratio > 0.1 and ratio <= 0.45:\n",
        "        result.append(\"장방형\")\n",
        "    elif ratio > 0.45 and ratio <= 1.0:\n",
        "        result.append(\"타원형\")\n",
        "\n",
        "def detect_8to10(path):\n",
        "    src = cv2.imread(reverse(path))\n",
        "    dst = src.copy()\n",
        "\n",
        "    gray = cv2.cvtColor(src, cv2.COLOR_RGB2GRAY)\n",
        "    ret, binary = cv2.threshold(gray, 10, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "    contours, hierarchy = cv2.findContours(binary, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)\n",
        "    for i in contours:\n",
        "        M = cv2.moments(i)\n",
        "        cX = int(M['m10'] / M['m00'])\n",
        "        cY = int(M['m01'] / M['m00'])\n",
        "        \n",
        "        cv2.circle(dst, (cX, cY), 3, (0, 0, 255), -1)\n",
        "        cv2.drawContours(dst, [i], 0, (0, 0, 255), 2)\n",
        "\n",
        "        setLabel(dst, i, '')\n",
        "        (x, y, w, h) = cv2.boundingRect(i)\n",
        "    if w > h:\n",
        "      ratio = h / w\n",
        "    elif h > w:\n",
        "      ratio = w / h\n",
        "    elif h == w:\n",
        "      ratio = h / w\n",
        "\n",
        "    if ratio > 0.1 and ratio <= 0.65:\n",
        "        result.append(\"장방형\")\n",
        "    elif ratio > 0.65 and ratio <= 1.0:\n",
        "        result.append(\"팔각형\")\n",
        "\n",
        "def detect_11to12(path):\n",
        "    src = cv2.imread(reverse(path))\n",
        "    dst = src.copy()\n",
        "\n",
        "    gray = cv2.cvtColor(src, cv2.COLOR_RGB2GRAY)\n",
        "    ret, binary = cv2.threshold(gray, 10, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "    contours, hierarchy = cv2.findContours(binary, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)\n",
        "    for i in contours:\n",
        "        M = cv2.moments(i)\n",
        "        cX = int(M['m10'] / M['m00'])\n",
        "        cY = int(M['m01'] / M['m00'])\n",
        "        \n",
        "        cv2.circle(dst, (cX, cY), 3, (0, 0, 255), -1)\n",
        "        cv2.drawContours(dst, [i], 0, (0, 0, 255), 2)\n",
        "\n",
        "        setLabel(dst, i, '')\n",
        "        (x, y, w, h) = cv2.boundingRect(i)\n",
        "    if w > h:\n",
        "      ratio = h / w\n",
        "    elif h > w:\n",
        "      ratio = w / h\n",
        "    elif h == w:\n",
        "      ratio = h / w\n",
        "\n",
        "    if ratio > 0.1 and ratio <= 0.45:\n",
        "        result.append(\"장방형\")\n",
        "    elif ratio > 0.9 and ratio <= 1.0:\n",
        "        result.append(\"사각형\")\n",
        "\n",
        "def detect_13to14(path):\n",
        "    src = cv2.imread(reverse(path))\n",
        "    dst = src.copy()\n",
        "\n",
        "    gray = cv2.cvtColor(src, cv2.COLOR_RGB2GRAY)\n",
        "    ret, binary = cv2.threshold(gray, 10, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "    contours, hierarchy = cv2.findContours(binary, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)\n",
        "    for i in contours:\n",
        "        M = cv2.moments(i)\n",
        "        cX = int(M['m10'] / M['m00'])\n",
        "        cY = int(M['m01'] / M['m00'])\n",
        "        \n",
        "        cv2.circle(dst, (cX, cY), 3, (0, 0, 255), -1)\n",
        "        cv2.drawContours(dst, [i], 0, (0, 0, 255), 2)\n",
        "\n",
        "        setLabel(dst, i, '')\n",
        "        (x, y, w, h) = cv2.boundingRect(i)\n",
        "    if w > h:\n",
        "      ratio = h / w\n",
        "    elif h > w:\n",
        "      ratio = w / h\n",
        "    elif h == w:\n",
        "      ratio = h / w\n",
        "\n",
        "    if ratio > 0.1 and ratio <= 0.45:\n",
        "        result.append(\"장방형\")\n",
        "    elif ratio > 0.45 and ratio <= 0.9:\n",
        "        result.append(\"타원형\")\n",
        "    elif ratio > 0.9 and ratio <= 1.0:\n",
        "        result.append(\"사각형\")\n",
        "\n",
        "def detect_15to16(path):\n",
        "    src = cv2.imread(reverse(path))\n",
        "    dst = src.copy()\n",
        "\n",
        "    gray = cv2.cvtColor(src, cv2.COLOR_RGB2GRAY)\n",
        "    ret, binary = cv2.threshold(gray, 10, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "    contours, hierarchy = cv2.findContours(binary, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)\n",
        "    for i in contours:\n",
        "        M = cv2.moments(i)\n",
        "        cX = int(M['m10'] / M['m00'])\n",
        "        cY = int(M['m01'] / M['m00'])\n",
        "        \n",
        "        cv2.circle(dst, (cX, cY), 3, (0, 0, 255), -1)\n",
        "        cv2.drawContours(dst, [i], 0, (0, 0, 255), 2)\n",
        "\n",
        "        setLabel(dst, i, '')\n",
        "        (x, y, w, h) = cv2.boundingRect(i)\n",
        "    if w > h:\n",
        "      ratio = h / w\n",
        "    elif h > w:\n",
        "      ratio = w / h\n",
        "    elif h == w:\n",
        "      ratio = h / w\n",
        "\n",
        "    if ratio > 0.1 and ratio <= 0.45:\n",
        "        result.append(\"장방형\")\n",
        "    elif ratio > 0.45 and ratio <= 0.9:\n",
        "        result.append(\"타원형\")\n",
        "    elif ratio > 0.9 and ratio <= 1.0:\n",
        "        result.append(\"원형\")\n",
        "\n",
        "def detect_17to21(path):\n",
        "    src = cv2.imread(reverse(path))\n",
        "    dst = src.copy()\n",
        "\n",
        "    gray = cv2.cvtColor(src, cv2.COLOR_RGB2GRAY)\n",
        "    ret, binary = cv2.threshold(gray, 10, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "    contours, hierarchy = cv2.findContours(binary, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)\n",
        "    for i in contours:\n",
        "        M = cv2.moments(i)\n",
        "        cX = int(M['m10'] / M['m00'])\n",
        "        cY = int(M['m01'] / M['m00'])\n",
        "        \n",
        "        cv2.circle(dst, (cX, cY), 3, (0, 0, 255), -1)\n",
        "        cv2.drawContours(dst, [i], 0, (0, 0, 255), 2)\n",
        "\n",
        "        setLabel(dst, i, '')\n",
        "        (x, y, w, h) = cv2.boundingRect(i)\n",
        "    if w > h:\n",
        "      ratio = h / w\n",
        "    elif h > w:\n",
        "      ratio = w / h\n",
        "    elif h == w:\n",
        "      ratio = h / w\n",
        "\n",
        "    if ratio > 0.45 and ratio <= 0.9:\n",
        "        result.append(\"타원형\")\n",
        "    elif ratio > 0.9 and ratio <= 1.0:\n",
        "        result.append(\"원형\")\n",
        "\n",
        "def centroid_histogram(clt):\n",
        "\t# grab the number of different clusters and create a histogram\n",
        "\t# based on the number of pixels assigned to each cluster\n",
        "\tnumLabels = np.arange(0, len(np.unique(clt.labels_)) + 1)\n",
        "\t(hist, _) = np.histogram(clt.labels_, bins = numLabels)\n",
        "\n",
        "\t# normalize the histogram, such that it sums to one\n",
        "\thist = hist.astype(\"float\")\n",
        "\thist /= hist.sum()\n",
        "\n",
        "\t# return the histogram\n",
        "\treturn hist\n",
        "\n",
        "def plot_colors(hist, centroids):\n",
        "\t# initialize the bar chart representing the relative frequency\n",
        "\t# of each of the colors\n",
        "\tbar = np.zeros((50, 300, 3), dtype = \"uint8\")\n",
        "\tstartX = 0\n",
        "\n",
        "\t# loop over the percentage of each cluster and the color of\n",
        "\t# each cluster\n",
        "\tfor (percent, color) in zip(hist, centroids):\n",
        "\t\t# plot the relative percentage of each cluster\n",
        "\t\tendX = startX + (percent * 300)\n",
        "\t\tcv2.rectangle(bar, (int(startX), 0), (int(endX), 50),\n",
        "\t\t\tcolor.astype(\"uint8\").tolist(), -1)\n",
        "\t\tstartX = endX\n",
        "\t\n",
        "\t# return the bar chart\n",
        "\treturn bar\n",
        "\n",
        "def first_largest_number(arr):\n",
        "    unique_nums = set(arr)\n",
        "    sorted_nums = sorted(unique_nums, reverse=True)\n",
        "    return sorted_nums[0]  \n",
        "\n",
        "def second_largest_number(arr):\n",
        "    unique_nums = set(arr)\n",
        "    sorted_nums = sorted(unique_nums, reverse=True)\n",
        "    return sorted_nums[1]\n",
        "\n",
        "'그레이 스케일'\n",
        "def mtjin_bgr2gray(bgr_img):\n",
        "    # BGR 색상값\n",
        "    b = bgr_img[:, :, 0]\n",
        "    g = bgr_img[:, :, 1]\n",
        "    r = bgr_img[:, :, 2]\n",
        "    result = ((0.299 * r) + (0.587 * g) + (0.114 * b))\n",
        "    # imshow 는 CV_8UC3 이나 CV_8UC1 형식을 위한 함수이므로 타입변환\n",
        "    return result.astype(np.uint8)\n",
        "\n",
        "'히스토그램 평활화'\n",
        "def histogram_equalization(img):\n",
        "  src = cv2.imread(img, cv2.IMREAD_GRAYSCALE)\n",
        "  dst = cv2.equalizeHist(src)\n",
        "  #cv2_imshow(dst)\n",
        "  cv2.imwrite(\"histogram_eq.jpg\", dst)\n",
        "\n",
        "'노이즈 제거(OCR)'\n",
        "def rm_noise(img):\n",
        "  src = cv2.imread(img, cv2.IMREAD_COLOR)\n",
        "  denoised_img = cv2.fastNlMeansDenoisingColored(src, None, 15, 15, 5, 10)\n",
        "  #cv2_imshow(src)\n",
        "  #cv2_imshow(denoised_img)\n",
        "  cv2.imwrite(\"denoise.jpg\", denoised_img)\n",
        "\n",
        "'노이즈 제거(제형)'\n",
        "def rm_noise2(img):\n",
        "  src = cv2.imread(img, cv2.IMREAD_COLOR)\n",
        "  denoised_img = cv2.fastNlMeansDenoisingColored(src, None, 15, 15, 5, 10)\n",
        "  #cv2_imshow(src)\n",
        "  #cv2_imshow(denoised_img)\n",
        "  cv2.imwrite(\"denoise2.jpg\", denoised_img)\n",
        "\n",
        "'OCR'\n",
        "def ocr(img):\n",
        "  reader = easyocr.Reader(['ko', 'en'])\n",
        "  output = reader.readtext(img, detail = 0)\n",
        "  joined_str = \"\".join(output) \n",
        "  #print(joined_str)\n",
        "  result.append(joined_str)\n",
        "\n",
        "def main():\n",
        "  %cd /content\n",
        "  args = easydict.EasyDict({\n",
        "      \"image\": True,\n",
        "      \"clusters\": 3\n",
        "  })\n",
        "\n",
        "  path3 = '/content/drive/MyDrive/remove_images/' # 경로 변경\n",
        "  file_list3 = os.listdir(path3)\n",
        "  file_list_py3 = [file for file in file_list3 if file.endswith('.jpg')] ##\n",
        "  for k in range(len(file_list_py3)):\n",
        "      try:\n",
        "        first_path = binary('/content/drive/MyDrive/remove_images/' + (str)(k+1) + 'rmbg.jpg')\n",
        "        cont(first_path)\n",
        "        image = cv2.imread('/content/drive/MyDrive/remove_images/' + (str)(k+1) + 'rmbg.jpg')\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        image = image.reshape((image.shape[0] * image.shape[1], 3))\n",
        "\n",
        "        input_img = cv2.imread('/content/drive/MyDrive/remove_images/' + (str)(k+1) + 'rmbg.jpg', cv2.IMREAD_GRAYSCALE)\n",
        "        cv2.imwrite(\"gray.jpg\", input_img)\n",
        "\n",
        "        clt = KMeans(n_clusters = args[\"clusters\"])\n",
        "        clt.fit(image)\n",
        "\n",
        "        hist = centroid_histogram(clt)\n",
        "        bar = plot_colors(hist, clt.cluster_centers_)\n",
        "\n",
        "        temp = clt.cluster_centers_\n",
        "        color_value = temp.astype(\"uint8\").tolist() #세 컬러의 rgb값\n",
        "        second_num = second_largest_number(hist) #히스토그램에서 두 번째로 큰 값(두 번째 색)\n",
        "\n",
        "        for i in range(3): #두 번째로 큰 값의 인덱스를 구함\n",
        "          if (second_num == hist[i]):\n",
        "            color_idx = i\n",
        "\n",
        "        if((color_value[color_idx][0] < 20) and (color_value[color_idx][1]) < 20 and (color_value[color_idx][2] < 20)):\n",
        "          first_num = first_largest_number(hist)\n",
        "          for i in range(3): #첫 번째로 큰 값의 인덱스를 구함\n",
        "            if (first_num == hist[i]):\n",
        "              color_idx = i\n",
        "\n",
        "        color_bgr = np.array([[[color_value[color_idx][2],color_value[color_idx][1],color_value[color_idx][0]]]], dtype=np.uint8)\n",
        "        color_hsv = cv2.cvtColor(color_bgr, cv2.COLOR_BGR2HSV)\n",
        "        h, s, v = cv2.split(color_hsv)\n",
        "\n",
        "        H.append(h)\n",
        "        S.append(s)\n",
        "        V.append(v)\n",
        "\n",
        "        Sum.append(h+s+v)\n",
        "        tmp.append(\"(\" + str(h) + \",\" + str(s) + \",\" + str(v) + \")\")\n",
        "\n",
        "        #[색상] STEP1. R+G+B, ABS(R-G)+ABS(R-B)+ABS(G-B)값을 기준으로 하여 검정, 하양 구분\n",
        "        # color_sum(색상합) = R+G+B\n",
        "        # color_diff(색상차) = ABS(R-G)+ABS(R-B)+ABS(G-B)\n",
        "        color_sum = color_value[color_idx][0] + color_value[color_idx][1] + color_value[color_idx][2]\n",
        "        color_diff = abs(color_value[color_idx][0]-color_value[color_idx][1]) + abs(color_value[color_idx][0]-color_value[color_idx][2]) + abs(color_value[color_idx][1]-color_value[color_idx][2])\n",
        "\n",
        "        # 검정 및 하양의 검사 대상을 확보하기 위해, 색상차를 비롯한 채도(S) 및 명도(V)를 추가적으로 활용한다.\n",
        "        if(color_diff<30 or s<30 or v<50):\n",
        "          if((color_sum>=0 and color_sum<350)):\n",
        "            result.append(\"검정\")\n",
        "          elif((color_sum>=350 and color_sum<766)):\n",
        "            result.append(\"하양\")\n",
        "\n",
        "        #[색상] STEP2. RGB -> HSV 변환을 통해 H(색상값)를 기준으로 하여 빨강, 노랑, 초록, 파랑 구분\n",
        "        # OpenCV의 HSV에 대한 H 최대값은 180이다.\n",
        "\n",
        "        # STEP2-1. 빨강에 대한 구분(빨강, 주황, 갈색, 분홍)\n",
        "        else:\n",
        "          if((h>=0 and h<20) or (h>=150 and h<180)):\n",
        "            result.append(\"빨강\")\n",
        "\n",
        "          #STEP2-2. 노랑에 대한 구분\n",
        "          elif(h>=20 and h<37):\n",
        "            result.append(\"노랑\")\n",
        "\n",
        "          #STEP2-3. 초록에 대한 구분(연두, 초록)\n",
        "          elif(h>=37 and h<81):\n",
        "            result.append(\"초록\")\n",
        "\n",
        "          #STEP2-4. 파랑에 대한 구분(청록, 파랑, 남색, 보라색, 자주색)\n",
        "          elif(h>=81 and h<150):\n",
        "            result.append(\"파랑\")\n",
        "\n",
        "        histogram_equalization(\"/content/gray.jpg\")\n",
        "        rm_noise(\"/content/histogram_eq.jpg\")\n",
        "        rm_noise(\"/content/histogram_eq.jpg\")\n",
        "        rm_noise(\"/content/denoise.jpg\")\n",
        "        rm_noise(\"/content/denoise.jpg\")\n",
        "        ocr(\"/content/denoise.jpg\")\n",
        "\n",
        "        print((str)(k+1) + \"번 이미지의 [최종 분석결과] : \" + str(result))\n",
        "        result.clear()\n",
        "      except Exception as e:\n",
        "          print(\"[ERROR] \"+str(k+1)+\"번째 이미지에 대해 에러가 발생했습니다.\")\n",
        "          continue\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\t  main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrypdrNY1m9l",
        "outputId": "7a5a5107-fc39-4fd8-c94f-b095c7daed7a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1번 이미지의 [최종 분석결과] : ['원형', '빨강', '80']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2번 이미지의 [최종 분석결과] : ['원형', '빨강', '0']\n",
            "[ERROR] 3번째 이미지에 대해 에러가 발생했습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4번 이미지의 [최종 분석결과] : ['원형', '빨강', '']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5번 이미지의 [최종 분석결과] : ['원형', '빨강', '80']\n",
            "[ERROR] 6번째 이미지에 대해 에러가 발생했습니다.\n",
            "[ERROR] 7번째 이미지에 대해 에러가 발생했습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8번 이미지의 [최종 분석결과] : ['원형', '하양', 'TGFFz']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9번 이미지의 [최종 분석결과] : ['타원형', '초록', 'PG']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10번 이미지의 [최종 분석결과] : ['장방형', '초록', '선다{급시노코프']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11번 이미지의 [최종 분석결과] : ['타원형', '빨강', 'TWLQQ']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12번 이미지의 [최종 분석결과] : ['원형', '빨강', 'TWLQQ']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13번 이미지의 [최종 분석결과] : ['타원형', '빨강', '']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14번 이미지의 [최종 분석결과] : ['원형', '파랑', \"'[29\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15번 이미지의 [최종 분석결과] : ['사각형', '파랑', 'CEn']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16번 이미지의 [최종 분석결과] : ['사각형', '파랑', 'ILE80']\n"
          ]
        }
      ]
    }
  ]
}
